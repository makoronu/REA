# ğŸ•·ï¸ REA ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ä»•æ§˜

## ğŸ“‹ æ¦‚è¦
- **ç”Ÿæˆæ—¥æ™‚**: 2025-09-18 07:09:31
- **å¯¾è±¡ã‚µã‚¤ãƒˆ**: ãƒ›ãƒ¼ãƒ ã‚ºï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: rea-scraper
- **æ¤œå‡ºãƒ•ã‚¡ã‚¤ãƒ«æ•°**: 29

## ğŸ¯ ä¸»è¦æ©Ÿèƒ½
- **URLåé›†**: ç‰©ä»¶ä¸€è¦§ãƒšãƒ¼ã‚¸ã‹ã‚‰ç‰©ä»¶URLã‚’åé›†
- **è©³ç´°æŠ½å‡º**: å„ç‰©ä»¶ãƒšãƒ¼ã‚¸ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’æŠ½å‡º
- **ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ç‰©ä»¶ç”»åƒã®è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- **ãƒ‡ãƒ¼ã‚¿ä¿å­˜**: PostgreSQLã«è‡ªå‹•ä¿å­˜

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
```
rea-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ scrapers/            # ã‚µã‚¤ãƒˆåˆ¥ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
â”‚   â”‚   â”œâ”€â”€ base/            # åŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”‚   â””â”€â”€ homes/           # ãƒ›ãƒ¼ãƒ ã‚ºå¯¾å¿œ
â”‚   â”œâ”€â”€ utils/               # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â”‚   â”œâ”€â”€ selenium_manager.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ process_manager.py
â”‚   â””â”€â”€ config/              # è¨­å®šç®¡ç†
â”œâ”€â”€ data/                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ
â”œâ”€â”€ logs/                    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
â””â”€â”€ requirements.txt         # ä¾å­˜é–¢ä¿‚
```

## ğŸ”§ å®Ÿè¡Œæ–¹æ³•

### URLåé›†
```bash
#cd rea-scraper
source ../venv/bin/activate
python -m src.main collect-urls --max-pages 10
```

### ãƒãƒƒãƒå‡¦ç†
```bash
python -m src.main process-batch --batch-size 10 --show-sample
```

### å…¨è‡ªå‹•å‡¦ç†
```bash
python -m src.main process-all --batch-size 10 --interval 300 --save
```

### çµ±è¨ˆç¢ºèª
```bash
python -m src.main queue-stats
```

## ğŸ› ï¸ ä¸»è¦ã‚¯ãƒ©ã‚¹
- **HomesPropertyScraper**: ãƒ›ãƒ¼ãƒ ã‚ºå°‚ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
- **SeleniumManager**: ãƒ–ãƒ©ã‚¦ã‚¶åˆ¶å¾¡ãƒ»Botå¯¾ç­–
- **URLQueue**: URLç®¡ç†ãƒ»æ°¸ç¶šåŒ–
- **DatabaseSaver**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- **å‡¦ç†é€Ÿåº¦**: ç´„11ç§’/ç‰©ä»¶
- **æˆåŠŸç‡**: 100%ï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œåˆ†ï¼‰
- **åé›†å®Ÿç¸¾**: 279URLï¼ˆ96ä»¶æœ‰åŠ¹ï¼‰

## ğŸ¤– DBæ¥ç¶šçµ±ä¸€å¯¾å¿œ
- **å¾“æ¥**: å€‹åˆ¥ã®DBæ¥ç¶šå‡¦ç†
- **æ–°æ–¹å¼**: `shared/database.py` ä½¿ç”¨æ¨å¥¨
- **æ¥ç¶šç¢ºèª**: `python shared/database.py`

## ğŸ¤– ä½¿ç”¨ä¾‹
```bash
# ç’°å¢ƒèµ·å‹•
#cd /Users/yaguchimakoto/my_programing/REA
source venv/bin/activate
#cd rea-scraper

# å¯¾è©±å‹å®Ÿè¡Œ
./scripts/start_scraping.sh

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
nohup ./scripts/monitor_scraper.sh > logs/monitor.log 2>&1 &
```

---

## ğŸ“¦ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

### æ¦‚è¦

ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’REAã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹éš›ã€**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒãƒƒãƒ”ãƒ³ã‚°**ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
ã‚³ãƒ¼ãƒ‰ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã›ãšã€DBãƒ†ãƒ¼ãƒ–ãƒ«ã§ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’ç®¡ç†ã™ã‚‹ã€‚

### ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ 

| ãƒ†ãƒ¼ãƒ–ãƒ« | å½¹å‰² |
|---------|------|
| `import_field_mappings` | ã‚½ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ â†’ REAã‚«ãƒ©ãƒ ã®å¯¾å¿œ |
| `import_value_mappings` | å€¤ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«ï¼ˆä¾‹: "æœ¨é€ " â†’ "1:æœ¨é€ "ï¼‰ |
| `master_options` | REAã®é¸æŠè‚¢å®šç¾©ï¼ˆcode â†’ labelï¼‰ |

### ä½¿ã„æ–¹

```python
from app.services.zoho.mapper import MetaDrivenMapper

# source_type ã‚’å¤‰ãˆã‚‹ã ã‘ã§ä»–ã‚µã‚¤ãƒˆã«å¯¾å¿œ
mapper = MetaDrivenMapper(source_type="suumo")  # or "homes", "athome"
result = mapper.map_record(scraped_data)

# çµæœ
# {
#   "properties": {"property_type": "1", "price": 1500, ...},
#   "land_info": {"land_area": 200.5, "use_district": "5", ...},
#   "building_info": {"building_structure": "1", ...},
#   "amenities": {...}
# }
```

### æ–°ã—ã„ã‚µã‚¤ãƒˆå¯¾å¿œæ‰‹é †

1. **import_value_mappingsã«ãƒãƒƒãƒ”ãƒ³ã‚°è¿½åŠ **
   ```sql
   INSERT INTO import_value_mappings (source_type, field_name, source_value, target_value)
   VALUES
     ('suumo', 'building_structure', 'æœ¨é€ ', '1:æœ¨é€ '),
     ('suumo', 'building_structure', 'é‰„éª¨', '3:é‰„éª¨é€ '),
     ('suumo', 'building_structure', '', '0:æœªè¨­å®š');
   ```

2. **import_field_mappingsã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œè¿½åŠ **
   ```sql
   INSERT INTO import_field_mappings (source_type, source_field, target_table, target_column, transform_type)
   VALUES
     ('suumo', 'tatemono_kouzou', 'building_info', 'building_structure', 'value_map'),
     ('suumo', 'kakaku', 'properties', 'price', 'numeric');
   ```

3. **Mapperã‚’ä½¿ã£ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**
   ```python
   mapper = MetaDrivenMapper(source_type="suumo")
   for item in scraped_items:
       result = mapper.map_record(item)
       # DBã«ä¿å­˜
   ```

### é‡è¦ãªãƒ«ãƒ¼ãƒ«

- **ç©ºæ–‡å­—/NULLã®å‡¦ç†**: `import_value_mappings`ã«ç©ºæ–‡å­—â†’0:æœªè¨­å®šã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å¿…ãšç™»éŒ²
- **master_optionsã¨ã®æ•´åˆæ€§**: target_valueã®codeã¯master_optionsã«å­˜åœ¨ã™ã‚‹ã“ã¨
- **ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¦æ­¢**: å¤‰æ›ãƒ«ãƒ¼ãƒ«ã¯å…¨ã¦DBã§ç®¡ç†
