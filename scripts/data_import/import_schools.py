#!/usr/bin/env python3
"""
å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: å›½åœŸæ•°å€¤æƒ…å ± å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ (P29)
URL: https://nlftp.mlit.go.jp/ksj/gml/datalist/KsjTmplt-P29.html
å½¢å¼: GeoJSON (P29-21_GML.zip)

å¯¾è±¡:
- å°å­¦æ ¡ (16001)
- ä¸­å­¦æ ¡ (16002)
- ä¸­ç­‰æ•™è‚²å­¦æ ¡ (16003)
- é«˜ç­‰å­¦æ ¡ (16004)
- é«˜ç­‰å°‚é–€å­¦æ ¡ (16005)
- çŸ­æœŸå¤§å­¦ (16006)
- å¤§å­¦ (16007)
- å¹¼ç¨šåœ’ (16011)
- ç‰¹åˆ¥æ”¯æ´å­¦æ ¡ (16012)
- èªå®šã“ã©ã‚‚åœ’ (16013)
- ç¾©å‹™æ•™è‚²å­¦æ ¡ (16014)
- å„ç¨®å­¦æ ¡ (16015)
- å°‚ä¿®å­¦æ ¡ (16016)

ä½¿ç”¨æ–¹æ³•:
    cd ~/my_programing/REA
    PYTHONPATH=~/my_programing/REA python3 scripts/data_import/import_schools.py
"""

import json
import os
import sys
import urllib.request
import zipfile
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parents[2]))
from shared.database import READatabase

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL
DOWNLOAD_URL = "https://nlftp.mlit.go.jp/ksj/gml/data/P29/P29-21/P29-21_GML.zip"
DATA_DIR = Path(__file__).parents[2] / "data" / "mlit_schools"
ZIP_FILE = DATA_DIR / "P29-21_GML.zip"
GEOJSON_FILE = DATA_DIR / "P29-21.geojson"

# å­¦æ ¡åˆ†é¡ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
CODE_MAPPING = {
    16001: ('elementary_school', 'å°å­¦æ ¡'),
    16002: ('junior_high_school', 'ä¸­å­¦æ ¡'),
    16003: ('secondary_school', 'ä¸­ç­‰æ•™è‚²å­¦æ ¡'),
    16004: ('high_school', 'é«˜ç­‰å­¦æ ¡'),
    16005: ('technical_college', 'é«˜ç­‰å°‚é–€å­¦æ ¡'),
    16006: ('junior_college', 'çŸ­æœŸå¤§å­¦'),
    16007: ('university', 'å¤§å­¦'),
    16011: ('kindergarten', 'å¹¼ç¨šåœ’'),
    16012: ('special_needs_school', 'ç‰¹åˆ¥æ”¯æ´å­¦æ ¡'),
    16013: ('certified_childcare', 'èªå®šã“ã©ã‚‚åœ’'),
    16014: ('compulsory_school', 'ç¾©å‹™æ•™è‚²å­¦æ ¡'),
    16015: ('miscellaneous_school', 'å„ç¨®å­¦æ ¡'),
    16016: ('vocational_school', 'å°‚ä¿®å­¦æ ¡'),
}

# éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰â†’åå‰
PREF_NAMES = {
    '01': 'åŒ—æµ·é“', '02': 'é’æ£®çœŒ', '03': 'å²©æ‰‹çœŒ', '04': 'å®®åŸçœŒ', '05': 'ç§‹ç”°çœŒ',
    '06': 'å±±å½¢çœŒ', '07': 'ç¦å³¶çœŒ', '08': 'èŒ¨åŸçœŒ', '09': 'æ ƒæœ¨çœŒ', '10': 'ç¾¤é¦¬çœŒ',
    '11': 'åŸ¼ç‰çœŒ', '12': 'åƒè‘‰çœŒ', '13': 'æ±äº¬éƒ½', '14': 'ç¥å¥ˆå·çœŒ', '15': 'æ–°æ½ŸçœŒ',
    '16': 'å¯Œå±±çœŒ', '17': 'çŸ³å·çœŒ', '18': 'ç¦äº•çœŒ', '19': 'å±±æ¢¨çœŒ', '20': 'é•·é‡çœŒ',
    '21': 'å²é˜œçœŒ', '22': 'é™å²¡çœŒ', '23': 'æ„›çŸ¥çœŒ', '24': 'ä¸‰é‡çœŒ', '25': 'æ»‹è³€çœŒ',
    '26': 'äº¬éƒ½åºœ', '27': 'å¤§é˜ªåºœ', '28': 'å…µåº«çœŒ', '29': 'å¥ˆè‰¯çœŒ', '30': 'å’Œæ­Œå±±çœŒ',
    '31': 'é³¥å–çœŒ', '32': 'å³¶æ ¹çœŒ', '33': 'å²¡å±±çœŒ', '34': 'åºƒå³¶çœŒ', '35': 'å±±å£çœŒ',
    '36': 'å¾³å³¶çœŒ', '37': 'é¦™å·çœŒ', '38': 'æ„›åª›çœŒ', '39': 'é«˜çŸ¥çœŒ', '40': 'ç¦å²¡çœŒ',
    '41': 'ä½è³€çœŒ', '42': 'é•·å´çœŒ', '43': 'ç†Šæœ¬çœŒ', '44': 'å¤§åˆ†çœŒ', '45': 'å®®å´çœŒ',
    '46': 'é¹¿å…å³¶çœŒ', '47': 'æ²–ç¸„çœŒ'
}


def download_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    if GEOJSON_FILE.exists():
        print(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {GEOJSON_FILE}")
        return

    print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {DOWNLOAD_URL}")
    urllib.request.urlretrieve(DOWNLOAD_URL, ZIP_FILE)

    print(f"è§£å‡ä¸­: {ZIP_FILE}")
    with zipfile.ZipFile(ZIP_FILE, 'r') as z:
        z.extractall(DATA_DIR)

    print("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")


def import_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    with open(GEOJSON_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"ç·ä»¶æ•°: {len(data['features'])}")

    db = READatabase()
    conn = db.get_connection()
    cur = conn.cursor()

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
    for code, (cat_code, _) in CODE_MAPPING.items():
        cur.execute("DELETE FROM m_facilities WHERE category_code = %s AND data_source = 'MLIT'", (cat_code,))
    conn.commit()
    print("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å®Œäº†")

    # ã‚«ãƒ†ã‚´ãƒªè¿½åŠ 
    for code, (cat_code, cat_name) in CODE_MAPPING.items():
        cur.execute("""
            INSERT INTO m_facility_categories (category_code, category_name, icon, display_order)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (category_code) DO NOTHING
        """, (cat_code, cat_name, 'ğŸ«', 0))
    conn.commit()

    # ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
    inserted = 0
    for feature in data['features']:
        props = feature['properties']
        coords = feature['geometry']['coordinates']

        school_code = props['P29_003']
        if school_code not in CODE_MAPPING:
            continue

        cat_code, _ = CODE_MAPPING[school_code]
        name = props['P29_004']
        address = props['P29_005']
        pref_code = props['P29_001'][:2]
        pref_name = PREF_NAMES.get(pref_code, '')
        lon, lat = coords[0], coords[1]

        cur.execute("""
            INSERT INTO m_facilities (category_code, name, address, prefecture_code, prefecture_name,
                                      latitude, longitude, location, data_source, external_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s)
        """, (cat_code, name, address, pref_code, pref_name, lat, lon, lon, lat, 'MLIT', props['P29_002']))
        inserted += 1

        if inserted % 10000 == 0:
            print(f"{inserted}ä»¶æŠ•å…¥...")
            conn.commit()

    conn.commit()
    print(f"å®Œäº†: {inserted}ä»¶æŠ•å…¥")

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
    cur.execute("""
        UPDATE m_data_sources
        SET last_updated = CURRENT_DATE, updated_at = CURRENT_TIMESTAMP
        WHERE source_name = 'å›½åœŸæ•°å€¤æƒ…å ± å­¦æ ¡ãƒ‡ãƒ¼ã‚¿'
    """)
    conn.commit()

    cur.close()
    conn.close()


if __name__ == '__main__':
    download_data()
    import_data()
