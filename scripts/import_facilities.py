#!/usr/bin/env python3
"""
å›½åœŸæ•°å€¤æƒ…å ±ã‹ã‚‰æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
- P04: åŒ»ç™‚æ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿
- P13: éƒ½å¸‚å…¬åœ’ãƒ‡ãƒ¼ã‚¿
- P14: ç¦ç¥‰æ–½è¨­ãƒ‡ãƒ¼ã‚¿
- P27: æ–‡åŒ–æ–½è¨­ãƒ‡ãƒ¼ã‚¿
- P30: éƒµä¾¿å±€ãƒ‡ãƒ¼ã‚¿
"""
import os
import sys
import json
import zipfile
import tempfile
import urllib.request
from pathlib import Path
import shapefile  # pyshp

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))
from shared.database import READatabase

# ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ
DATA_DIR = Path(__file__).parent.parent / "data" / "facilities"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰
PREFECTURES = {
    "01": "åŒ—æµ·é“", "02": "é’æ£®çœŒ", "03": "å²©æ‰‹çœŒ", "04": "å®®åŸçœŒ", "05": "ç§‹ç”°çœŒ",
    "06": "å±±å½¢çœŒ", "07": "ç¦å³¶çœŒ", "08": "èŒ¨åŸçœŒ", "09": "æ ƒæœ¨çœŒ", "10": "ç¾¤é¦¬çœŒ",
    "11": "åŸ¼ç‰çœŒ", "12": "åƒè‘‰çœŒ", "13": "æ±äº¬éƒ½", "14": "ç¥å¥ˆå·çœŒ", "15": "æ–°æ½ŸçœŒ",
    "16": "å¯Œå±±çœŒ", "17": "çŸ³å·çœŒ", "18": "ç¦äº•çœŒ", "19": "å±±æ¢¨çœŒ", "20": "é•·é‡çœŒ",
    "21": "å²é˜œçœŒ", "22": "é™å²¡çœŒ", "23": "æ„›çŸ¥çœŒ", "24": "ä¸‰é‡çœŒ", "25": "æ»‹è³€çœŒ",
    "26": "äº¬éƒ½åºœ", "27": "å¤§é˜ªåºœ", "28": "å…µåº«çœŒ", "29": "å¥ˆè‰¯çœŒ", "30": "å’Œæ­Œå±±çœŒ",
    "31": "é³¥å–çœŒ", "32": "å³¶æ ¹çœŒ", "33": "å²¡å±±çœŒ", "34": "åºƒå³¶çœŒ", "35": "å±±å£çœŒ",
    "36": "å¾³å³¶çœŒ", "37": "é¦™å·çœŒ", "38": "æ„›åª›çœŒ", "39": "é«˜çŸ¥çœŒ", "40": "ç¦å²¡çœŒ",
    "41": "ä½è³€çœŒ", "42": "é•·å´çœŒ", "43": "ç†Šæœ¬çœŒ", "44": "å¤§åˆ†çœŒ", "45": "å®®å´çœŒ",
    "46": "é¹¿å…å³¶çœŒ", "47": "æ²–ç¸„çœŒ"
}


def download_data(data_type: str, pref_code: str) -> Path:
    """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥ã®URLè¨­å®š
    url_patterns = {
        'P04': ('P04-20', 'https://nlftp.mlit.go.jp/ksj/gml/data/P04/P04-20/P04-20_{}_GML.zip'),  # åŒ»ç™‚æ©Ÿé–¢
        'P13': ('P13-11', 'https://nlftp.mlit.go.jp/ksj/gml/data/P13/P13-11/P13-11_{}_GML.zip'),  # éƒ½å¸‚å…¬åœ’
        'P14': ('P14-15', 'https://nlftp.mlit.go.jp/ksj/gml/data/P14/P14-15/P14-15_{}_GML.zip'),  # ç¦ç¥‰æ–½è¨­
        'P27': ('P27-13', 'https://nlftp.mlit.go.jp/ksj/gml/data/P27/P27-13/P27-13_{}.zip'),  # æ–‡åŒ–æ–½è¨­
        'P30': ('P30-13', 'https://nlftp.mlit.go.jp/ksj/gml/data/P30/P30-13/P30-13_{}.zip'),  # éƒµä¾¿å±€ï¼ˆGMLãªã—ï¼‰
    }

    if data_type not in url_patterns:
        print(f"  âŒ ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {data_type}")
        return None

    prefix, url_template = url_patterns[data_type]
    url = url_template.format(pref_code)
    zip_path = DATA_DIR / f"{prefix}_{pref_code}_GML.zip"

    if zip_path.exists():
        print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: {zip_path.name}")
        return zip_path

    print(f"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {url}")
    try:
        urllib.request.urlretrieve(url, zip_path)
        return zip_path
    except Exception as e:
        print(f"  âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None


def parse_medical_geojson(geojson_path: Path) -> list:
    """åŒ»ç™‚æ©Ÿé–¢GeoJSONã‚’ãƒ‘ãƒ¼ã‚¹ (P04)"""
    with open(geojson_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    facilities = []

    for feature in data.get('features', []):
        props = feature.get('properties', {})
        geom = feature.get('geometry', {})

        if geom.get('type') != 'Point':
            continue

        coords = geom.get('coordinates', [])
        if len(coords) < 2:
            continue

        # P04_001: åŒ»ç™‚æ©Ÿé–¢åˆ†é¡ï¼ˆ1:ç—…é™¢, 2:ä¸€èˆ¬è¨ºç™‚æ‰€, 3:æ­¯ç§‘è¨ºç™‚æ‰€ï¼‰
        med_type = str(props.get('P04_001', ''))
        # P04_002: æ–½è¨­å
        name = props.get('P04_002', '') or ''
        # P04_003: ä½æ‰€
        address = props.get('P04_003', '') or ''

        # ã‚«ãƒ†ã‚´ãƒªæ±ºå®šï¼ˆç—…é™¢ or è¨ºç™‚æ‰€ï¼‰
        category = 'hospital' if med_type == '1' else 'clinic'

        facilities.append({
            'name': name,
            'address': address,
            'category_code': category,
            'latitude': coords[1],
            'longitude': coords[0],
            'metadata': {'type_code': med_type}
        })

    return facilities


def parse_park_shapefile(shp_path: Path) -> list:
    """éƒ½å¸‚å…¬åœ’Shapefileã‚’ãƒ‘ãƒ¼ã‚¹ (P13)"""
    facilities = []

    sf = shapefile.Reader(str(shp_path), encoding='cp932')
    fields = [f[0] for f in sf.fields[1:]]  # æœ€åˆã¯DeletionFlag

    for sr in sf.shapeRecords():
        shape = sr.shape
        record = dict(zip(fields, sr.record))

        # ãƒã‚¤ãƒ³ãƒˆã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if shape.shapeType != shapefile.POINT:
            continue

        coords = shape.points[0] if shape.points else None
        if not coords:
            continue

        # P13_003: å…¬åœ’å
        name = record.get('P13_003', '') or ''
        # P13_005: éƒ½é“åºœçœŒå, P13_006: å¸‚åŒºç”ºæ‘å
        pref = record.get('P13_005', '') or ''
        city = record.get('P13_006', '') or ''
        address = '{}{}'.format(pref, city)

        facilities.append({
            'name': name,
            'address': address,
            'category_code': 'park',
            'latitude': coords[1],  # shapefile: (lon, lat)
            'longitude': coords[0],
            'metadata': {}
        })

    return facilities


def parse_post_office_shapefile(shp_path: Path) -> list:
    """éƒµä¾¿å±€Shapefileã‚’ãƒ‘ãƒ¼ã‚¹ (P30)"""
    facilities = []

    sf = shapefile.Reader(str(shp_path), encoding='cp932')
    fields = [f[0] for f in sf.fields[1:]]

    for sr in sf.shapeRecords():
        shape = sr.shape
        record = dict(zip(fields, sr.record))

        if shape.shapeType != shapefile.POINT:
            continue

        coords = shape.points[0] if shape.points else None
        if not coords:
            continue

        # P30_005: éƒµä¾¿å±€å
        name = record.get('P30_005', '') or ''
        # P30_006: ä½æ‰€
        address = record.get('P30_006', '') or ''

        facilities.append({
            'name': name,
            'address': address,
            'category_code': 'post_office',
            'latitude': coords[1],
            'longitude': coords[0],
            'metadata': {}
        })

    return facilities


def parse_welfare_shapefile(shp_path: Path) -> list:
    """ç¦ç¥‰æ–½è¨­Shapefileã‚’ãƒ‘ãƒ¼ã‚¹ (P14)"""
    # ç¦ç¥‰æ–½è¨­å¤§åˆ†é¡ã‚³ãƒ¼ãƒ‰ â†’ ã‚«ãƒ†ã‚´ãƒª
    WELFARE_CATEGORIES = {
        16: 'nursery',      # å…ç«¥ç¦ç¥‰ â†’ ä¿è‚²æ‰€
        19: 'nursing_home', # é«˜é½¢è€…ç¦ç¥‰ â†’ è€äººãƒ›ãƒ¼ãƒ 
    }

    facilities = []

    sf = shapefile.Reader(str(shp_path), encoding='cp932')
    fields = [f[0] for f in sf.fields[1:]]

    for sr in sf.shapeRecords():
        shape = sr.shape
        record = dict(zip(fields, sr.record))

        if shape.shapeType != shapefile.POINT:
            continue

        coords = shape.points[0] if shape.points else None
        if not coords:
            continue

        # P14_004: ç¦ç¥‰æ–½è¨­å¤§åˆ†é¡ã‚³ãƒ¼ãƒ‰
        welfare_code = record.get('P14_004', 0) or 0
        category = WELFARE_CATEGORIES.get(welfare_code, 'welfare')

        # P14_007: æ–½è¨­å
        name = record.get('P14_007', '') or ''
        # P14_001 + P14_002 + P14_003: ä½æ‰€
        pref = record.get('P14_001', '') or ''
        city = record.get('P14_002', '') or ''
        addr = record.get('P14_003', '') or ''
        address = '{}{}{}'.format(pref, city, addr)

        facilities.append({
            'name': name,
            'address': address,
            'category_code': category,
            'latitude': coords[1],
            'longitude': coords[0],
            'metadata': {'welfare_code': welfare_code}
        })

    return facilities


def parse_culture_shapefile(shp_path: Path) -> list:
    """æ–‡åŒ–æ–½è¨­Shapefileã‚’ãƒ‘ãƒ¼ã‚¹ (P27)"""
    facilities = []

    sf = shapefile.Reader(str(shp_path), encoding='cp932')
    fields = [f[0] for f in sf.fields[1:]]

    for sr in sf.shapeRecords():
        shape = sr.shape
        record = dict(zip(fields, sr.record))

        if shape.shapeType != shapefile.POINT:
            continue

        coords = shape.points[0] if shape.points else None
        if not coords:
            continue

        # P27_005: æ–½è¨­å
        name = record.get('P27_005', '') or ''
        # P27_006: ä½æ‰€
        address = record.get('P27_006', '') or ''

        # æ–½è¨­åã§åˆ†é¡ï¼ˆå›³æ›¸é¤¨ã‚’ç‰¹å®šï¼‰
        if 'å›³æ›¸é¤¨' in name:
            category = 'library'
        else:
            category = 'culture'  # ç¾è¡“é¤¨ãƒ»åšç‰©é¤¨ç­‰

        facilities.append({
            'name': name,
            'address': address,
            'category_code': category,
            'latitude': coords[1],
            'longitude': coords[0],
            'metadata': {}
        })

    return facilities


def extract_and_parse(zip_path: Path, data_type: str) -> list:
    """ZIPã‚’å±•é–‹ã—ã¦ãƒ‘ãƒ¼ã‚¹ï¼ˆGeoJSON â†’ Shapefile ã®é †ã§æ¢ã™ï¼‰"""
    with tempfile.TemporaryDirectory() as tmpdir:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            zf.extractall(tmpdir)

        tmppath = Path(tmpdir)

        # 1. GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆã—ã¦æ¢ã™
        geojson_files = list(tmppath.glob("**/*.geojson"))
        if geojson_files:
            geojson_path = geojson_files[0]
            if data_type == 'P04':
                return parse_medical_geojson(geojson_path)

        # 2. Shapefileã‚’æ¢ã™
        shp_files = [f for f in tmppath.glob("**/*.shp") if not f.name.startswith("KS-META")]
        if shp_files:
            shp_path = shp_files[0]
            if data_type == 'P13':
                return parse_park_shapefile(shp_path)
            elif data_type == 'P14':
                return parse_welfare_shapefile(shp_path)
            elif data_type == 'P27':
                return parse_culture_shapefile(shp_path)
            elif data_type == 'P30':
                return parse_post_office_shapefile(shp_path)

        return []


def insert_facilities(cur, facilities: list, pref_code: str, data_source: str):
    """æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚’DBã«æŒ¿å…¥"""
    pref_name = PREFECTURES.get(pref_code, '')

    for facility in facilities:
        try:
            cur.execute("""
                INSERT INTO m_facilities (
                    category_code, name, address,
                    prefecture_code, prefecture_name,
                    latitude, longitude, location,
                    data_source, metadata
                ) VALUES (
                    %s, %s, %s,
                    %s, %s,
                    %s, %s,
                    ST_SetSRID(ST_MakePoint(%s, %s), 4326),
                    %s, %s
                )
            """, (
                facility['category_code'], facility['name'], facility['address'],
                pref_code, pref_name,
                facility['latitude'], facility['longitude'],
                facility['longitude'], facility['latitude'],
                data_source, json.dumps(facility.get('metadata', {}))
            ))
        except Exception as e:
            print(f"    æŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {facility['name']} - {e}")


def import_data_type(data_type: str, description: str):
    """ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print(f"\n{'='*60}")
    print(f"å›½åœŸæ•°å€¤æƒ…å ± {description}ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ({data_type})")
    print(f"{'='*60}")

    db = READatabase()
    conn = db.get_connection()
    cur = conn.cursor()

    try:
        total_count = 0

        for pref_code, pref_name in PREFECTURES.items():
            print(f"\nğŸ“ {pref_name}({pref_code})...")

            zip_path = download_data(data_type, pref_code)
            if not zip_path:
                continue

            facilities = extract_and_parse(zip_path, data_type)
            print(f"  æ–½è¨­æ•°: {len(facilities)}")

            insert_facilities(cur, facilities, pref_code, data_type)
            conn.commit()

            total_count += len(facilities)

        print(f"\nâœ… {description}ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {total_count}ä»¶")
        return total_count

    except Exception as e:
        conn.rollback()
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    finally:
        cur.close()
        conn.close()


def main():
    import argparse
    parser = argparse.ArgumentParser(description='æ–½è¨­ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ')
    parser.add_argument('--type', choices=['P04', 'P13', 'P14', 'P27', 'P30', 'all'], default='all',
                       help='ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—')
    args = parser.parse_args()

    results = {}

    if args.type in ['P04', 'all']:
        results['åŒ»ç™‚æ©Ÿé–¢'] = import_data_type('P04', 'åŒ»ç™‚æ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿')

    if args.type in ['P13', 'all']:
        results['å…¬åœ’'] = import_data_type('P13', 'éƒ½å¸‚å…¬åœ’ãƒ‡ãƒ¼ã‚¿')

    if args.type in ['P14', 'all']:
        results['ç¦ç¥‰æ–½è¨­'] = import_data_type('P14', 'ç¦ç¥‰æ–½è¨­ãƒ‡ãƒ¼ã‚¿')

    if args.type in ['P27', 'all']:
        results['æ–‡åŒ–æ–½è¨­'] = import_data_type('P27', 'æ–‡åŒ–æ–½è¨­ãƒ‡ãƒ¼ã‚¿')

    if args.type in ['P30', 'all']:
        results['éƒµä¾¿å±€'] = import_data_type('P30', 'éƒµä¾¿å±€ãƒ‡ãƒ¼ã‚¿')

    print(f"\n{'='*60}")
    print("ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœ")
    print(f"{'='*60}")
    for name, count in results.items():
        print(f"  {name}: {count}ä»¶")


if __name__ == "__main__":
    main()
