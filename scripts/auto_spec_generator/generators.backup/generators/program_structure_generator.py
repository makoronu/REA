# generators/program_structure_generator.py
import sys
from pathlib import Path
from typing import Dict, Any
from .base_generator import BaseGenerator

class ProgramStructureGenerator(BaseGenerator):
    """ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ ä»•æ§˜ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def generate(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ ä»•æ§˜ç”Ÿæˆ"""
        try:
            # Pythonãƒ‘ã‚¹ã«ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’è¿½åŠ 
            sys.path.append(str(self.base_path))
            
            # ã‚³ãƒ¼ãƒ‰è§£æå™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from analyzers.code_analyzer import CodeAnalyzer
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’è§£æ
            analyzer = CodeAnalyzer(self.base_path)
            summary = analyzer.get_project_summary()
            
            content = f"""# ğŸ—ï¸ REAãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ ä»•æ§˜

## ğŸ“‹ ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {self.get_timestamp()}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹**: {self.base_path}
- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {summary['total_files']}
- **ç·é–¢æ•°æ•°**: {summary['total_functions']}
- **ç·ã‚¯ãƒ©ã‚¹æ•°**: {summary['total_classes']}
- **ç·è¡Œæ•°**: {summary['total_lines']:,}

## ğŸ“ˆ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥æ§‹é€ 

| No | ãƒ•ã‚¡ã‚¤ãƒ« | è¡Œæ•° | é–¢æ•°æ•° | ã‚¯ãƒ©ã‚¹æ•° | ç”¨é€” |
|----|----------|------|--------|----------|------|
"""
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´°
            for i, file_info in enumerate(summary['files'], 1):
                file_path = file_info['file_path']
                lines = file_info.get('lines', 0)
                func_count = len(file_info.get('functions', []))
                class_count = len(file_info.get('classes', []))
                purpose = self._classify_file_purpose(file_path, file_info)
                
                content += f"| {i} | `{file_path}` | {lines} | {func_count} | {class_count} | {purpose} |\n"
            
            content += f"""
## ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼
- **å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {summary['total_lines'] // max(summary['total_files'], 1)}è¡Œ
- **é–¢æ•°å¯†åº¦**: {summary['total_functions'] / max(summary['total_files'], 1):.1f}é–¢æ•°/ãƒ•ã‚¡ã‚¤ãƒ«
- **ã‚¯ãƒ©ã‚¹å¯†åº¦**: {summary['total_classes'] / max(summary['total_files'], 1):.1f}ã‚¯ãƒ©ã‚¹/ãƒ•ã‚¡ã‚¤ãƒ«

## ğŸ¯ ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è©³ç´°

"""
            
            # ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ
            for file_info in summary['files']:
                if file_info.get('lines', 0) > 50 or len(file_info.get('classes', [])) > 0:
                    content += self._generate_file_detail(file_info)
            
            # ä¾å­˜é–¢ä¿‚åˆ†æ
            content += self._generate_dependency_analysis(summary['files'])
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            program_dir = self.get_output_dir("05_program_structure")
            self.save_content(content, program_dir / "current_structure.md")
            
            self.print_status(f"âœ… ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ : {summary['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå®Œäº†")
            return {
                "success": True,
                "files": summary['total_files'],
                "functions": summary['total_functions'],
                "classes": summary['total_classes'],
                "lines": summary['total_lines']
            }
            
        except Exception as e:
            self.print_status(f"âŒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æœ€å°é™ä»•æ§˜æ›¸ç”Ÿæˆ
            fallback_content = f"""# âŒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼

## ğŸš¨ ã‚¨ãƒ©ãƒ¼å†…å®¹
```
{e}
```

## ğŸ”§ å¯¾å‡¦æ–¹æ³•
1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ç¢ºèª: {self.base_path}
2. Pythonç’°å¢ƒç¢ºèª: venvæœ‰åŠ¹åŒ–
3. analyzers ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª

**ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚åˆ»**: {self.get_timestamp()}
"""
            
            program_dir = self.get_output_dir("05_program_structure")
            self.save_content(fallback_content, program_dir / "current_structure.md")
            
            return {"success": False, "error": str(e)}
    
    def _classify_file_purpose(self, file_path: str, file_info: Dict[str, Any]) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”¨é€”ã‚’è‡ªå‹•åˆ†é¡"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        if "main.py" in file_path:
            return "ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"
        elif "test" in file_path.lower():
            return "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«"
        elif "config" in file_path.lower():
            return "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"
        elif "generator" in file_path:
            return "ä»•æ§˜æ›¸ç”Ÿæˆå™¨"
        elif "scraper" in file_path:
            return "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½"
        elif "api" in file_path:
            return "APIé–¢é€£"
        elif "database" in file_path:
            return "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ"
        elif "analyzer" in file_path:
            return "åˆ†æãƒ»è§£ææ©Ÿèƒ½"
        elif "shared" in file_path:
            return "å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒª"
        elif "__init__.py" in file_path:
            return "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–"
        
        # ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã®å†…å®¹ã«ã‚ˆã‚‹åˆ¤å®š
        classes = file_info.get('classes', [])
        functions = file_info.get('functions', [])
        
        if len(classes) > len(functions):
            return "ã‚¯ãƒ©ã‚¹ä¸­å¿ƒãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
        elif len(functions) > 5:
            return "ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
        elif file_info.get('lines', 0) > 200:
            return "å¤§è¦æ¨¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
        else:
            return "æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
    
    def _generate_file_detail(self, file_info: Dict[str, Any]) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°æƒ…å ±ç”Ÿæˆ"""
        file_path = file_info['file_path']
        content = f"\n### {file_path}\n"
        content += f"**è¡Œæ•°**: {file_info.get('lines', 0)}  \n"
        content += f"**è¤‡é›‘åº¦**: {file_info.get('complexity', 0)}  \n"
        
        # docstring
        if file_info.get('docstring'):
            content += f"**èª¬æ˜**: {file_info['docstring'][:100]}...  \n"
        
        # ã‚¯ãƒ©ã‚¹ä¸€è¦§
        classes = file_info.get('classes', [])
        if classes:
            content += f"**ã‚¯ãƒ©ã‚¹**: "
            class_names = [cls['name'] for cls in classes]
            content += ", ".join(class_names) + "  \n"
        
        # ä¸»è¦é–¢æ•°
        functions = file_info.get('functions', [])
        if functions:
            content += f"**é–¢æ•°**: "
            func_names = [func['name'] for func in functions[:5]]
            content += ", ".join(func_names)
            if len(functions) > 5:
                content += f" ...ä»–{len(functions)-5}é–¢æ•°"
            content += "  \n"
        
        return content
    
    def _generate_dependency_analysis(self, files: list) -> str:
        """ä¾å­˜é–¢ä¿‚åˆ†æ"""
        content = "\n## ğŸ”— ä¾å­˜é–¢ä¿‚åˆ†æ\n\n"
        
        # importçµ±è¨ˆ
        all_imports = []
        internal_imports = []
        external_imports = []
        
        for file_info in files:
            imports = file_info.get('imports', [])
            for imp in imports:
                module = imp.get('module', '')
                all_imports.append(module)
                
                if any(keyword in module for keyword in ['rea', 'shared', 'generators', 'analyzers']):
                    internal_imports.append(module)
                else:
                    external_imports.append(module)
        
        # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨çŠ¶æ³
        content += "### å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨çŠ¶æ³\n"
        external_counts = {}
        for lib in external_imports:
            if lib and not lib.startswith('.'):
                root_lib = lib.split('.')[0]
                external_counts[root_lib] = external_counts.get(root_lib, 0) + 1
        
        sorted_libs = sorted(external_counts.items(), key=lambda x: x[1], reverse=True)
        for lib, count in sorted_libs[:10]:
            content += f"- **{lib}**: {count}å›ä½¿ç”¨  \n"
        
        # å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜
        content += "\n### å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜\n"
        internal_counts = {}
        for module in internal_imports:
            if module:
                internal_counts[module] = internal_counts.get(module, 0) + 1
        
        sorted_internal = sorted(internal_counts.items(), key=lambda x: x[1], reverse=True)
        for module, count in sorted_internal[:10]:
            content += f"- **{module}**: {count}å›å‚ç…§  \n"
        
        return content