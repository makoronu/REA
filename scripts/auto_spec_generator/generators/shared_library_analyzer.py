# generators/shared_library_analyzer.py - å…¨é–¢æ•°å®Œå…¨æ¤œå‡ºç‰ˆ
import os
import re
from pathlib import Path
from typing import Any, Dict, List


class SharedLibraryAnalyzer:
    """shared/ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå®Œå…¨åˆ†æã‚¯ãƒ©ã‚¹ï¼ˆå…¨é–¢æ•°æ¤œå‡ºç‰ˆï¼‰"""

    def __init__(self, base_path: Path, output_dir: Path):
        self.base_path = Path(base_path)
        self.output_dir = Path(output_dir)
        self.shared_dir = self.base_path / "shared"

    def generate(self) -> Dict[str, Any]:
        """shared/ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå®Œå…¨åˆ†æå®Ÿè¡Œ"""
        print("   ğŸ“š shared/ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå®Œå…¨åˆ†æä¸­...")

        if not self.shared_dir.exists():
            print("   âŒ shared/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return {"status": "error", "message": "shared directory not found"}

        # Python ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
        python_files = list(self.shared_dir.glob("*.py"))
        python_files = [f for f in python_files if f.name != "__init__.py"]

        print(f"   ğŸ” åˆ†æå¯¾è±¡: {len(python_files)}ãƒ•ã‚¡ã‚¤ãƒ«")

        analysis_results = {}

        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©³ç´°åˆ†æ
        for file_path in python_files:
            print(f"\n   ğŸ“ {file_path.name}")

            try:
                file_analysis = self._analyze_python_file(file_path)
                analysis_results[file_path.name] = file_analysis

                # ãƒ•ã‚¡ã‚¤ãƒ«docstringè¡¨ç¤º
                if file_analysis.get("file_docstring"):
                    doc_summary = file_analysis["file_docstring"].split("\n")[0][:60]
                    print(f"      ğŸ“ {doc_summary}")

                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæƒ…å ±è¡¨ç¤º
                imports = file_analysis.get("imports", [])
                if imports:
                    print(f"      ğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {len(imports)}å€‹")
                    for imp in imports[:3]:  # æœ€åˆã®3å€‹ã¾ã§è¡¨ç¤º
                        print(f"      â”‚   â”œâ”€â”€ {imp}")
                    if len(imports) > 3:
                        print(f"      â”‚   â””â”€â”€ ...ä»–{len(imports) - 3}å€‹")

                # ã‚¯ãƒ©ã‚¹æƒ…å ±è¡¨ç¤º
                classes = file_analysis.get("classes", {})
                if classes:
                    for class_name, class_info in classes.items():
                        print(f"      â”œâ”€â”€ ğŸ—ï¸ {class_name} ã‚¯ãƒ©ã‚¹")
                        if class_info.get("docstring"):
                            doc_summary = class_info["docstring"].split("\n")[0][:50]
                            print(f"      â”‚   â””â”€â”€ ğŸ“ {doc_summary}")

                        methods = class_info.get("methods", [])
                        if methods:
                            for method in methods[:5]:  # æœ€åˆã®5å€‹ã¾ã§è¡¨ç¤º
                                print(
                                    f"      â”‚   â”œâ”€â”€ {method['name']}({method['params']}) {method['return_type']}"
                                )
                                if method.get("docstring"):
                                    doc_summary = method["docstring"].split("\n")[0][
                                        :40
                                    ]
                                    print(f"      â”‚   â”‚   â””â”€â”€ ğŸ“ {doc_summary}")
                            if len(methods) > 5:
                                print(f"      â”‚   â””â”€â”€ ...ä»–{len(methods) - 5}å€‹ãƒ¡ã‚½ãƒƒãƒ‰")

                # é–¢æ•°æƒ…å ±è¡¨ç¤ºï¼ˆå…¨é–¢æ•°ï¼‰
                functions = file_analysis.get("functions", {})
                if functions:
                    for func_name, func_info in functions.items():
                        params = func_info.get("params", "")
                        return_type = func_info.get("return_type", "")
                        print(f"      â”œâ”€â”€ âš™ï¸ {func_name}({params}) {return_type}")
                        if func_info.get("docstring"):
                            doc_summary = func_info["docstring"].split("\n")[0][:50]
                            print(f"      â”‚   â””â”€â”€ ğŸ“ {doc_summary}")

                # å®šæ•°æƒ…å ±è¡¨ç¤º
                constants = file_analysis.get("constants", [])
                if constants:
                    print(f"      â”œâ”€â”€ ğŸ“Š å®šæ•°: {len(constants)}å€‹")
                    for const in constants[:3]:  # æœ€åˆã®3å€‹ã¾ã§è¡¨ç¤º
                        print(f"      â”‚   â”œâ”€â”€ {const}")
                    if len(constants) > 3:
                        print(f"      â”‚   â””â”€â”€ ...ä»–{len(constants) - 3}å€‹")

                # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                line_count = file_analysis.get("line_count", 0)
                total_functions = (
                    len(classes.get(list(classes.keys())[0], {}).get("methods", []))
                    if classes
                    else 0
                )
                total_functions += len(functions)
                print(f"      â””â”€â”€ ğŸ“Š ç·è¡Œæ•°: {line_count}è¡Œ, ç·é–¢æ•°æ•°: {total_functions}å€‹")

            except Exception as e:
                print(f"      âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                analysis_results[file_path.name] = {"error": str(e)}

        # åˆ†æçµæœã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
        self._generate_complete_reference(analysis_results)

        print(f"\n   âœ… shared/ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ†æå®Œäº†: {len(python_files)}ãƒ•ã‚¡ã‚¤ãƒ«")

        return {
            "status": "success",
            "files_analyzed": len(python_files),
            "analysis_results": analysis_results,
        }

    def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æï¼ˆå…¨é–¢æ•°æ¤œå‡ºç‰ˆï¼‰"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            lines = content.split("\n")

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ãƒ™ãƒ«ã®docstringæŠ½å‡º
            file_docstring = self._extract_file_docstring(content)

            # ã‚¯ãƒ©ã‚¹è©³ç´°åˆ†æ
            classes = self._extract_classes_detailed(content)

            # å…¨é–¢æ•°è©³ç´°åˆ†æï¼ˆã‚¯ãƒ©ã‚¹å†…å¤–å…¨ã¦ï¼‰
            functions = self._extract_all_functions_detailed(content)

            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©³ç´°åˆ†æ
            imports = self._extract_imports_detailed(lines)

            # å®šæ•°æ¤œç´¢ï¼ˆå¤§æ–‡å­—ã®å¤‰æ•°ï¼‰
            constants = []
            for line in lines:
                match = re.match(r"^([A-Z_]+)\s*=", line.strip())
                if match:
                    constants.append(match.group(1))

            return {
                "file_name": file_path.name,
                "file_size": file_path.stat().st_size,
                "line_count": len(lines),
                "file_docstring": file_docstring,
                "classes": classes,
                "functions": functions,
                "imports": imports,
                "constants": constants,
            }

        except Exception as e:
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {e}"}

    def _extract_file_docstring(self, content: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ãƒ™ãƒ«ã®docstringæŠ½å‡º"""
        # ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­ã®ä¸‰é‡ã‚¯ã‚©ãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’æ¢ã™
        match = re.search(r'^"""(.*?)"""', content, re.DOTALL | re.MULTILINE)
        if match:
            return match.group(1).strip()

        match = re.search(r"^'''(.*?)'''", content, re.DOTALL | re.MULTILINE)
        if match:
            return match.group(1).strip()

        return ""

    def _extract_classes_detailed(self, content: str) -> Dict[str, Dict]:
        """ã‚¯ãƒ©ã‚¹ã®è©³ç´°åˆ†æï¼ˆdocstringãƒ»ãƒ¡ã‚½ãƒƒãƒ‰è¾¼ã¿ï¼‰"""
        classes = {}

        # ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’æ¤œç´¢
        class_pattern = r"^class\s+(\w+).*?:\s*\n((?:.*\n)*?)(?=^class|\Z)"
        class_matches = re.finditer(class_pattern, content, re.MULTILINE)

        for match in class_matches:
            class_name = match.group(1)
            class_body = match.group(2)

            # ã‚¯ãƒ©ã‚¹ã®docstringæŠ½å‡º
            docstring = ""
            docstring_match = re.search(
                r'^\s*"""(.*?)"""', class_body, re.DOTALL | re.MULTILINE
            )
            if docstring_match:
                docstring = docstring_match.group(1).strip()

            # ãƒ¡ã‚½ãƒƒãƒ‰æŠ½å‡º
            methods = []
            method_pattern = r"^\s*def\s+(\w+)\s*\((.*?)\)\s*(?:->\s*([^:]+?))?\s*:"
            method_matches = re.finditer(method_pattern, class_body, re.MULTILINE)

            for method_match in method_matches:
                method_name = method_match.group(1)
                params = method_match.group(2) if method_match.group(2) else ""
                return_type = (
                    f"-> {method_match.group(3).strip()}"
                    if method_match.group(3)
                    else ""
                )

                # ãƒ¡ã‚½ãƒƒãƒ‰ã®docstringæŠ½å‡º
                method_docstring = ""
                method_start = method_match.end()
                remaining_body = class_body[method_start:]
                method_doc_match = re.search(
                    r'^\s*"""(.*?)"""', remaining_body, re.DOTALL | re.MULTILINE
                )
                if method_doc_match:
                    method_docstring = method_doc_match.group(1).strip()

                methods.append(
                    {
                        "name": method_name,
                        "params": params,
                        "return_type": return_type,
                        "docstring": method_docstring,
                    }
                )

            classes[class_name] = {"docstring": docstring, "methods": methods}

        return classes

    def _extract_all_functions_detailed(self, content: str) -> Dict[str, Dict]:
        """å…¨é–¢æ•°ã®è©³ç´°åˆ†æï¼ˆã‚¯ãƒ©ã‚¹å†…å¤–å…¨ã¦å¯¾è±¡ï¼‰"""
        functions = {}

        lines = content.split("\n")

        for i, line in enumerate(lines):
            # def ã§å§‹ã¾ã‚‹è¡Œã‚’å…¨ã¦æ¤œå‡º
            if re.match(r"\s*def\s+", line):
                match = re.match(
                    r"\s*def\s+(\w+)\s*\((.*?)\)\s*(?:->\s*([^:]+?))?\s*:", line
                )
                if match:
                    func_name = match.group(1)
                    params = match.group(2) if match.group(2) else ""
                    return_type = (
                        f"-> {match.group(3).strip()}" if match.group(3) else ""
                    )

                    # docstringæŠ½å‡ºï¼ˆæ¬¡ã®è¡Œã‹ã‚‰æ¢ã™ï¼‰
                    docstring = ""
                    for j in range(i + 1, min(i + 10, len(lines))):
                        if j < len(lines):
                            next_line = lines[j].strip()
                            if next_line.startswith('"""') or next_line.startswith(
                                "'''"
                            ):
                                # docstringç™ºè¦‹
                                if (
                                    next_line.count('"""') >= 2
                                    or next_line.count("'''") >= 2
                                ):
                                    # åŒã˜è¡Œã§å®Œçµ
                                    docstring = (
                                        next_line.strip('"""').strip("'''").strip()
                                    )
                                else:
                                    # è¤‡æ•°è¡Œdocstring
                                    doc_lines = [next_line.strip('"""').strip("'''")]
                                    for k in range(j + 1, min(j + 5, len(lines))):
                                        if k < len(lines):
                                            doc_line = lines[k]
                                            if '"""' in doc_line or "'''" in doc_line:
                                                doc_lines.append(
                                                    doc_line.split('"""')[0].split(
                                                        "'''"
                                                    )[0]
                                                )
                                                break
                                            doc_lines.append(doc_line.strip())
                                    docstring = " ".join(doc_lines).strip()
                                break
                            elif next_line and not next_line.startswith("#"):
                                # docstringãŒãªã„å ´åˆã¯çµ‚äº†
                                break

                    functions[func_name] = {
                        "params": params,
                        "return_type": return_type,
                        "docstring": docstring,
                    }

        return functions

    def _extract_imports_detailed(self, lines: List[str]) -> List[str]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®è©³ç´°æŠ½å‡º"""
        imports = []

        for line in lines:
            line = line.strip()
            if line.startswith("import ") or line.startswith("from "):
                # ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»
                if "#" in line:
                    line = line[: line.index("#")].strip()
                imports.append(line)

        return imports

    def _generate_complete_reference(self, analysis_results: Dict[str, Any]):
        """å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹Markdownãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆå…¨é–¢æ•°ç‰ˆï¼‰"""
        shared_dir = self.output_dir / "04_shared"
        shared_dir.mkdir(parents=True, exist_ok=True)

        reference_file = shared_dir / "complete_library_reference.md"

        content = []
        content.append("# ğŸ”¬ shared/ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆå…¨é–¢æ•°æ¤œå‡ºç‰ˆï¼‰")
        content.append("")
        content.append("**ç”Ÿæˆæ—¥æ™‚**: è‡ªå‹•ç”Ÿæˆ")
        content.append(f"**åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(analysis_results)}")
        content.append("")
        content.append("## ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
        content.append("")

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«
        content.append("| No | ãƒ•ã‚¡ã‚¤ãƒ«å | ã‚µã‚¤ã‚º | ã‚¯ãƒ©ã‚¹æ•° | å…¨é–¢æ•°æ•° | è¡Œæ•° | èª¬æ˜ |")
        content.append(
            "|----|------------|--------|----------|----------|------|------|"
        )

        for i, (filename, analysis) in enumerate(analysis_results.items(), 1):
            if "error" in analysis:
                content.append(f"| {i} | {filename} | - | - | - | - | âŒ ã‚¨ãƒ©ãƒ¼ |")
            else:
                size_kb = analysis.get("file_size", 0) // 1024
                class_count = len(analysis.get("classes", {}))

                # å…¨é–¢æ•°æ•°è¨ˆç®—ï¼ˆã‚¯ãƒ©ã‚¹å†…ãƒ¡ã‚½ãƒƒãƒ‰ + ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«é–¢æ•°ï¼‰
                total_func_count = len(analysis.get("functions", {}))
                for class_info in analysis.get("classes", {}).values():
                    total_func_count += len(class_info.get("methods", []))

                line_count = analysis.get("line_count", 0)
                file_doc = analysis.get("file_docstring", "")
                doc_summary = file_doc.split("\n")[0][:30] if file_doc else "-"
                content.append(
                    f"| {i} | {filename} | {size_kb}KB | {class_count} | {total_func_count} | {line_count} | {doc_summary} |"
                )

        content.append("")

        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±
        for filename, analysis in analysis_results.items():
            if "error" in analysis:
                content.append(f"## ğŸ“ {filename}")
                content.append("")
                content.append(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {analysis['error']}")
                content.append("")
                continue

            content.append(f"## ğŸ“ {filename}")
            content.append("")

            # ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜
            if analysis.get("file_docstring"):
                content.append("### ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜")
                content.append("```")
                content.append(analysis["file_docstring"])
                content.append("```")
                content.append("")

            # åŸºæœ¬æƒ…å ±
            size_kb = analysis.get("file_size", 0) // 1024
            line_count = analysis.get("line_count", 0)

            # å…¨é–¢æ•°æ•°è¨ˆç®—
            total_func_count = len(analysis.get("functions", {}))
            for class_info in analysis.get("classes", {}).values():
                total_func_count += len(class_info.get("methods", []))

            content.append(f"- **ã‚µã‚¤ã‚º**: {size_kb}KB")
            content.append(f"- **è¡Œæ•°**: {line_count}è¡Œ")
            content.append(f"- **ç·é–¢æ•°æ•°**: {total_func_count}å€‹")
            content.append("")

            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©³ç´°
            imports = analysis.get("imports", [])
            if imports:
                content.append("### ğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©³ç´°")
                content.append("")
                for imp in imports:
                    content.append(f"- `{imp}`")
                content.append("")

            # ã‚¯ãƒ©ã‚¹è©³ç´°
            classes = analysis.get("classes", {})
            if classes:
                content.append("### ğŸ—ï¸ ã‚¯ãƒ©ã‚¹è©³ç´°")
                content.append("")

                for class_name, class_info in classes.items():
                    content.append(f"#### `{class_name}` ã‚¯ãƒ©ã‚¹")
                    content.append("")

                    if class_info.get("docstring"):
                        content.append("**èª¬æ˜**:")
                        content.append("```")
                        content.append(class_info["docstring"])
                        content.append("```")
                        content.append("")

                    methods = class_info.get("methods", [])
                    if methods:
                        content.append(f"**ãƒ¡ã‚½ãƒƒãƒ‰ä¸€è¦§**: {len(methods)}å€‹")
                        content.append("")

                        for method in methods:
                            method_sig = f"`{method['name']}({method['params']}) {method['return_type']}`"
                            content.append(f"- {method_sig}")
                            if method.get("docstring"):
                                content.append(
                                    f"  - ğŸ“ {method['docstring'].split(chr(10))[0]}"
                                )
                            content.append("")

            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«é–¢æ•°è©³ç´°
            functions = analysis.get("functions", {})
            if functions:
                content.append("### âš™ï¸ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«é–¢æ•°")
                content.append("")

                for func_name, func_info in functions.items():
                    func_sig = f"`{func_name}({func_info['params']}) {func_info['return_type']}`"
                    content.append(f"#### {func_sig}")
                    content.append("")

                    if func_info.get("docstring"):
                        content.append("**èª¬æ˜**:")
                        content.append("```")
                        content.append(func_info["docstring"])
                        content.append("```")
                        content.append("")

            # å®šæ•°ä¸€è¦§
            constants = analysis.get("constants", [])
            if constants:
                content.append("### ğŸ“Š å®šæ•°")
                content.append("")

                for const in constants:
                    content.append(f"- `{const}`")
                content.append("")

            content.append("---")
            content.append("")

        # ã‚µãƒãƒªãƒ¼
        total_classes = sum(
            len(a.get("classes", {}))
            for a in analysis_results.values()
            if "error" not in a
        )
        total_functions = 0
        total_lines = sum(
            a.get("line_count", 0)
            for a in analysis_results.values()
            if "error" not in a
        )

        for analysis in analysis_results.values():
            if "error" not in analysis:
                total_functions += len(analysis.get("functions", {}))
                for class_info in analysis.get("classes", {}).values():
                    total_functions += len(class_info.get("methods", []))

        content.append("## ğŸ“Š ã‚µãƒãƒªãƒ¼")
        content.append("")
        content.append(f"- **åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(analysis_results)}")
        content.append(f"- **ç·ã‚¯ãƒ©ã‚¹æ•°**: {total_classes}")
        content.append(f"- **ç·é–¢æ•°æ•°**: {total_functions}")
        content.append(f"- **ç·è¡Œæ•°**: {total_lines}")
        content.append("")
        content.append("---")
        content.append("")
        content.append("*ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼ˆå…¨é–¢æ•°æ¤œå‡ºç‰ˆï¼‰*")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
        with open(reference_file, "w", encoding="utf-8") as f:
            f.write("\n".join(content))

        print(f"   âœ… å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ç”Ÿæˆ: {reference_file}")
