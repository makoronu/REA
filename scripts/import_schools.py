#!/usr/bin/env python3
"""
å›½åœŸæ•°å€¤æƒ…å ±ã‹ã‚‰å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
- P29: å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ï¼ˆå°å­¦æ ¡ãƒ»ä¸­å­¦æ ¡ãƒ»é«˜ç­‰å­¦æ ¡ç­‰ã®ä½ç½®ï¼‰
"""
import os
import sys
import json
import zipfile
import tempfile
import urllib.request
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))
from shared.database import READatabase

# ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ
DATA_DIR = Path(__file__).parent.parent / "data" / "schools"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰
PREFECTURES = {
    "01": "åŒ—æµ·é“", "02": "é’æ£®çœŒ", "03": "å²©æ‰‹çœŒ", "04": "å®®åŸçœŒ", "05": "ç§‹ç”°çœŒ",
    "06": "å±±å½¢çœŒ", "07": "ç¦å³¶çœŒ", "08": "èŒ¨åŸçœŒ", "09": "æ ƒæœ¨çœŒ", "10": "ç¾¤é¦¬çœŒ",
    "11": "åŸ¼ç‰çœŒ", "12": "åƒè‘‰çœŒ", "13": "æ±äº¬éƒ½", "14": "ç¥å¥ˆå·çœŒ", "15": "æ–°æ½ŸçœŒ",
    "16": "å¯Œå±±çœŒ", "17": "çŸ³å·çœŒ", "18": "ç¦äº•çœŒ", "19": "å±±æ¢¨çœŒ", "20": "é•·é‡çœŒ",
    "21": "å²é˜œçœŒ", "22": "é™å²¡çœŒ", "23": "æ„›çŸ¥çœŒ", "24": "ä¸‰é‡çœŒ", "25": "æ»‹è³€çœŒ",
    "26": "äº¬éƒ½åºœ", "27": "å¤§é˜ªåºœ", "28": "å…µåº«çœŒ", "29": "å¥ˆè‰¯çœŒ", "30": "å’Œæ­Œå±±çœŒ",
    "31": "é³¥å–çœŒ", "32": "å³¶æ ¹çœŒ", "33": "å²¡å±±çœŒ", "34": "åºƒå³¶çœŒ", "35": "å±±å£çœŒ",
    "36": "å¾³å³¶çœŒ", "37": "é¦™å·çœŒ", "38": "æ„›åª›çœŒ", "39": "é«˜çŸ¥çœŒ", "40": "ç¦å²¡çœŒ",
    "41": "ä½è³€çœŒ", "42": "é•·å´çœŒ", "43": "ç†Šæœ¬çœŒ", "44": "å¤§åˆ†çœŒ", "45": "å®®å´çœŒ",
    "46": "é¹¿å…å³¶çœŒ", "47": "æ²–ç¸„çœŒ"
}

# å­¦æ ¡åˆ†é¡ã‚³ãƒ¼ãƒ‰ï¼ˆæ•´æ•°å‹ï¼‰
SCHOOL_TYPES = {
    16001: "å°å­¦æ ¡",
    16002: "ä¸­å­¦æ ¡",
    16003: "ç¾©å‹™æ•™è‚²å­¦æ ¡",
    16004: "é«˜ç­‰å­¦æ ¡",
    16005: "ä¸­ç­‰æ•™è‚²å­¦æ ¡",
    16006: "ç‰¹åˆ¥æ”¯æ´å­¦æ ¡",
    16007: "é«˜ç­‰å°‚é–€å­¦æ ¡",
    16008: "çŸ­æœŸå¤§å­¦",
    16009: "å¤§å­¦",
    16011: "å¹¼ç¨šåœ’",
    16012: "å¹¼ä¿é€£æºå‹èªå®šã“ã©ã‚‚åœ’",
    16013: "å°‚ä¿®å­¦æ ¡",
    16014: "å„ç¨®å­¦æ ¡",
    16015: "ãã®ä»–ã®æ•™è‚²æ–½è¨­",
    16016: "ä¿è‚²æ‰€ç­‰"
}

# ç®¡ç†è€…ã‚³ãƒ¼ãƒ‰ï¼ˆæ•´æ•°å‹ï¼‰
ADMIN_TYPES = {
    1: "å›½ç«‹",
    2: "å…¬ç«‹",
    3: "ç§ç«‹",
    4: "ç§ç«‹"  # 4ã‚‚ç§ç«‹ã¨ã—ã¦æ‰±ã†
}


def create_schools_table(cur):
    """å­¦æ ¡ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
    cur.execute("""
        CREATE TABLE IF NOT EXISTS m_schools (
            id SERIAL PRIMARY KEY,
            school_code VARCHAR(20) UNIQUE,
            school_type VARCHAR(20) NOT NULL,
            school_type_name VARCHAR(50),
            name VARCHAR(200) NOT NULL,
            address VARCHAR(500),
            prefecture_code VARCHAR(2),
            prefecture_name VARCHAR(20),
            admin_type VARCHAR(10),
            admin_type_name VARCHAR(20),
            is_closed BOOLEAN DEFAULT FALSE,
            latitude DECIMAL(10, 7),
            longitude DECIMAL(10, 7),
            location GEOMETRY(Point, 4326),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_m_schools_location
        ON m_schools USING GIST (location)
    """)
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_m_schools_type
        ON m_schools (school_type)
    """)
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_m_schools_prefecture
        ON m_schools (prefecture_code)
    """)
    print("âœ… m_schools ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")


def download_school_data(pref_code: str) -> Path:
    """éƒ½é“åºœçœŒåˆ¥ã®å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    # ä»¤å’Œ3å¹´åº¦ãƒ‡ãƒ¼ã‚¿ (P29-21)
    url = f"https://nlftp.mlit.go.jp/ksj/gml/data/P29/P29-21/P29-21_{pref_code}_GML.zip"
    zip_path = DATA_DIR / f"P29-21_{pref_code}_GML.zip"

    if zip_path.exists():
        print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: {zip_path.name}")
        return zip_path

    print(f"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {url}")
    try:
        urllib.request.urlretrieve(url, zip_path)
        return zip_path
    except Exception as e:
        print(f"  âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None


def parse_geojson(geojson_path: Path) -> list:
    """GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹"""
    with open(geojson_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    schools = []
    for feature in data.get('features', []):
        props = feature.get('properties', {})
        geom = feature.get('geometry', {})

        if geom.get('type') != 'Point':
            continue

        coords = geom.get('coordinates', [])
        if len(coords) < 2:
            continue

        school = {
            'school_code': str(props.get('P29_002', '')),
            'school_type': props.get('P29_003'),  # æ•´æ•°å‹ã®ã¾ã¾
            'name': props.get('P29_004', ''),
            'address': props.get('P29_005', ''),
            'admin_code': props.get('P29_006'),  # æ•´æ•°å‹ã®ã¾ã¾
            'is_closed': props.get('P29_007', 1) == 2,  # 2=ä¼‘æ ¡
            'longitude': coords[0],
            'latitude': coords[1]
        }
        schools.append(school)

    return schools


def parse_shapefile(shp_dir: Path) -> list:
    """Shapefileã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆpyshpä½¿ç”¨ï¼‰"""
    try:
        import shapefile
    except ImportError:
        print("  pyshpæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€‚pip install pyshp ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return []

    # P29ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    shp_files = list(shp_dir.glob("**/P29*.shp"))
    if not shp_files:
        return []

    schools = []
    for shp_file in shp_files:
        sf = shapefile.Reader(str(shp_file), encoding='cp932')

        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å–å¾—
        fields = [f[0] for f in sf.fields[1:]]

        for sr in sf.shapeRecords():
            props = dict(zip(fields, sr.record))

            if sr.shape.shapeType != 1:  # Point
                continue

            school = {
                'school_code': str(props.get('P29_002', '')),
                'school_type': str(props.get('P29_003', '')),
                'name': str(props.get('P29_004', '')),
                'address': str(props.get('P29_005', '')),
                'admin_code': str(props.get('P29_006', '')),
                'is_closed': str(props.get('P29_007', '0')) == '1',
                'longitude': sr.shape.points[0][0],
                'latitude': sr.shape.points[0][1]
            }
            schools.append(school)

    return schools


def extract_and_parse(zip_path: Path, pref_code: str) -> list:
    """ZIPã‚’å±•é–‹ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    with tempfile.TemporaryDirectory() as tmpdir:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            zf.extractall(tmpdir)

        tmppath = Path(tmpdir)

        # GeoJSONã‚’å„ªå…ˆçš„ã«æ¢ã™
        geojson_files = list(tmppath.glob("**/*.geojson"))
        if geojson_files:
            return parse_geojson(geojson_files[0])

        # Shapefileã‚’æ¢ã™
        return parse_shapefile(tmppath)


def insert_schools(cur, schools: list, pref_code: str):
    """å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ã‚’DBã«æŒ¿å…¥"""
    pref_name = PREFECTURES.get(pref_code, '')

    for school in schools:
        school_type = school['school_type']
        school_type_name = SCHOOL_TYPES.get(school_type, '')
        admin_type_name = ADMIN_TYPES.get(school['admin_code'], '')

        # å°å­¦æ ¡ãƒ»ä¸­å­¦æ ¡ãƒ»ç¾©å‹™æ•™è‚²å­¦æ ¡ã®ã¿ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
        if school_type not in [16001, 16002, 16003]:
            continue

        try:
            cur.execute("""
                INSERT INTO m_schools (
                    school_code, school_type, school_type_name, name, address,
                    prefecture_code, prefecture_name, admin_type, admin_type_name,
                    is_closed, latitude, longitude, location
                ) VALUES (
                    %s, %s, %s, %s, %s,
                    %s, %s, %s, %s,
                    %s, %s, %s,
                    ST_SetSRID(ST_MakePoint(%s, %s), 4326)
                )
                ON CONFLICT (school_code) DO UPDATE SET
                    name = EXCLUDED.name,
                    address = EXCLUDED.address,
                    is_closed = EXCLUDED.is_closed,
                    latitude = EXCLUDED.latitude,
                    longitude = EXCLUDED.longitude,
                    location = EXCLUDED.location
            """, (
                school['school_code'], school_type, school_type_name, school['name'], school['address'],
                pref_code, pref_name, school['admin_code'], admin_type_name,
                school['is_closed'], school['latitude'], school['longitude'],
                school['longitude'], school['latitude']
            ))
        except Exception as e:
            print(f"    æŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {school['name']} - {e}")


def main():
    print("=" * 60)
    print("å›½åœŸæ•°å€¤æƒ…å ± å­¦æ ¡ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    print("=" * 60)

    db = READatabase()
    conn = db.get_connection()
    cur = conn.cursor()

    try:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        create_schools_table(cur)
        conn.commit()

        total_count = 0

        # å…¨éƒ½é“åºœçœŒã‚’å‡¦ç†
        for pref_code, pref_name in PREFECTURES.items():
            print(f"\nğŸ“ {pref_name}({pref_code})...")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            zip_path = download_school_data(pref_code)
            if not zip_path:
                continue

            # ãƒ‘ãƒ¼ã‚¹
            schools = extract_and_parse(zip_path, pref_code)
            print(f"  å­¦æ ¡æ•°: {len(schools)}")

            # æŒ¿å…¥
            insert_schools(cur, schools, pref_code)
            conn.commit()

            total_count += len([s for s in schools if s['school_type'] in ['16001', '16002', '16003']])

        # æœ€çµ‚ç¢ºèª
        cur.execute("SELECT COUNT(*) FROM m_schools")
        db_count = cur.fetchone()[0]

        cur.execute("""
            SELECT school_type_name, COUNT(*)
            FROM m_schools
            GROUP BY school_type_name
            ORDER BY school_type_name
        """)
        type_counts = cur.fetchall()

        print("\n" + "=" * 60)
        print(f"âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {db_count}æ ¡")
        for type_name, count in type_counts:
            print(f"   - {type_name}: {count}æ ¡")
        print("=" * 60)

    except Exception as e:
        conn.rollback()
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    finally:
        cur.close()
        conn.close()


if __name__ == "__main__":
    main()
